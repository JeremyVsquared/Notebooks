{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with CNN's and Keras\n",
    "\n",
    "This task was the objective in a [kaggle competition](https://www.kaggle.com/c/sentiment-analysis-on-imdb-movie-reviews/leaderboard). At the time, the best performing submission evaluated by log loss was 0.24591 so we're trying to beat that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout, Dense, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 1000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_review_len = 1600\n",
    "embedding_vector_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build straight forward CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Embedding(top_words, embedding_vector_len, input_length=max_review_len))\n",
    "\n",
    "mdl.add(Convolution1D(64, 3, padding='same'))\n",
    "mdl.add(Convolution1D(32, 3, padding='same'))\n",
    "mdl.add(Convolution1D(16, 3, padding='same'))\n",
    "mdl.add(Flatten())\n",
    "mdl.add(Dropout(0.2))\n",
    "\n",
    "mdl.add(Dense(180, activation='sigmoid'))\n",
    "mdl.add(Dropout(0.2))\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 481s 19ms/step - loss: 0.4229 - acc: 0.8004\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 486s 19ms/step - loss: 0.3086 - acc: 0.8695\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 493s 20ms/step - loss: 0.2363 - acc: 0.9048\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 493s 20ms/step - loss: 0.1700 - acc: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x114e69710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.132\n",
      "[0.43232870185852051, 0.84131999999999996]\n"
     ]
    }
   ],
   "source": [
    "scores = mdl.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.432328701859\n",
      "acc: 84.132\n"
     ]
    }
   ],
   "source": [
    "nms = mdl.metrics_names\n",
    "print(\"{}: {}\".format(nms[0], scores[0]))\n",
    "print(\"{}: {}\".format(nms[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 483s 19ms/step - loss: 0.1245 - acc: 0.9516\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 509s 20ms/step - loss: 0.0966 - acc: 0.9628\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 494s 20ms/step - loss: 0.0767 - acc: 0.9716\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 455s 18ms/step - loss: 0.0661 - acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1157b2cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.660322692337\n",
      "acc: 82.288\n"
     ]
    }
   ],
   "source": [
    "scores = mdl.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "nms = mdl.metrics_names\n",
    "print(\"{}: {}\".format(nms[0], scores[0]))\n",
    "print(\"{}: {}\".format(nms[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing loss and accuracy are getting worse while the training loss and accuracy are getting better. It's probably overfitting, so moving on to another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slightly more complicated CNN model\n",
    "\n",
    "Adding a max pooling layer, bumping up the dropout, and doubling the CNN stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Embedding(top_words, embedding_vector_len, input_length=max_review_len))\n",
    "\n",
    "mdl.add(Convolution1D(64, 3, padding='same'))\n",
    "mdl.add(Convolution1D(32, 3, padding='same'))\n",
    "mdl.add(Convolution1D(16, 3, padding='same'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Dropout(0.25))\n",
    "\n",
    "mdl.add(Convolution1D(64, 3, padding='same'))\n",
    "mdl.add(Convolution1D(32, 3, padding='same'))\n",
    "mdl.add(Convolution1D(16, 3, padding='same'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Flatten())\n",
    "mdl.add(Dropout(0.25))\n",
    "\n",
    "mdl.add(Dense(180, activation='sigmoid'))\n",
    "mdl.add(Dropout(0.25))\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 493s 20ms/step - loss: 0.4351 - acc: 0.7875\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 490s 20ms/step - loss: 0.3274 - acc: 0.8590\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 488s 20ms/step - loss: 0.2942 - acc: 0.8770\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 561s 22ms/step - loss: 0.2709 - acc: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10c7e9990>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.299845308571\n",
      "acc: 87.376\n"
     ]
    }
   ],
   "source": [
    "scores = mdl.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "nms = mdl.metrics_names\n",
    "print(\"{}: {}\".format(nms[0], scores[0]))\n",
    "print(\"{}: {}\".format(nms[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 0.29984 we're not too far away from 0.24591 but I'm pretty sure we can do better than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complicated model\n",
    "\n",
    "messing with the convolution stacks after adding another, tweaking dropout to accomodate an extra layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Embedding(top_words, embedding_vector_len, input_length=max_review_len))\n",
    "\n",
    "mdl.add(Convolution1D(128, 3, padding='same'))\n",
    "mdl.add(Convolution1D(64, 3, padding='same'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Dropout(0.25))\n",
    "\n",
    "mdl.add(Convolution1D(128, 3, padding='same'))\n",
    "mdl.add(Convolution1D(64, 3, padding='same'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Dropout(0.25))\n",
    "\n",
    "mdl.add(Convolution1D(64, 3, padding='same'))\n",
    "mdl.add(Convolution1D(32, 3, padding='same'))\n",
    "mdl.add(Convolution1D(16, 3, padding='same'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Flatten())\n",
    "mdl.add(Dropout(0.25))\n",
    "\n",
    "mdl.add(Dense(256, activation='sigmoid'))\n",
    "mdl.add(Dropout(0.25))\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 1168s 47ms/step - loss: 0.4386 - acc: 0.7834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122c18590>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 1074s 43ms/step - loss: 0.3240 - acc: 0.8629\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 2153s 86ms/step - loss: 0.3019 - acc: 0.8738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f03a050>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 997s 40ms/step - loss: 0.2829 - acc: 0.8831\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 1123s 45ms/step - loss: 0.2616 - acc: 0.8941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x115694650>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.336828304973\n",
      "acc: 87.652\n"
     ]
    }
   ],
   "source": [
    "scores = mdl.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "nms = mdl.metrics_names\n",
    "print(\"{}: {}\".format(nms[0], scores[0]))\n",
    "print(\"{}: {}\".format(nms[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, well that did worse. Better accuracy, but worse on log loss.\n",
    "\n",
    "- Benchmark: 0.24591\n",
    "- Model 1: 0.29984\n",
    "- Model 2: 0.33682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive window CNN architecture\n",
    "\n",
    "altering our convolution stack to create progressively larger convolution windows, pooling in each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Embedding(top_words, embedding_vector_len, input_length=max_review_len))\n",
    "mdl.add(Dropout(0.25))\n",
    "\n",
    "mdl.add(Convolution1D(64, 3, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "mdl.add(Convolution1D(64, 4, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "mdl.add(Convolution1D(64, 5, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "mdl.add(Convolution1D(64, 6, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Flatten())\n",
    "\n",
    "mdl.add(Dropout(0.25))\n",
    "mdl.add(Dense(128, activation='relu'))\n",
    "mdl.add(Dropout(0.5))\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 630s 25ms/step - loss: 0.5141 - acc: 0.6956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12265eed0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 618s 25ms/step - loss: 0.2989 - acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12340bb10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 586s 23ms/step - loss: 0.2570 - acc: 0.8960\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 2470s 99ms/step - loss: 0.2287 - acc: 0.9077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f143710>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.265067278109\n",
      "acc: 88.836\n"
     ]
    }
   ],
   "source": [
    "scores = mdl.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "nms = mdl.metrics_names\n",
    "print(\"{}: {}\".format(nms[0], scores[0]))\n",
    "print(\"{}: {}\".format(nms[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better log loss & accuracy. Headed in the right direction.\n",
    "\n",
    "- Benchmark: 0.24591\n",
    "- Model 1: 0.29984\n",
    "- Model 2: 0.33682\n",
    "- Model 3: 0.26506\n",
    "\n",
    "This score would have gotten us a rank of 16 had it been entered into the contest.\n",
    "\n",
    "It doesn't appear to be overfitting so let's try a few more epochs and see where it goes. _Breaking best practices by introducing the test data to the training intervals for live updates. Should have split out a validation set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 787s 31ms/step - loss: 0.1992 - acc: 0.9217 - val_loss: 0.2792 - val_acc: 0.8837\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 773s 31ms/step - loss: 0.1714 - acc: 0.9327 - val_loss: 0.3630 - val_acc: 0.8631\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2702s 108ms/step - loss: 0.1469 - acc: 0.9436 - val_loss: 0.3249 - val_acc: 0.8754\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1102s 44ms/step - loss: 0.1167 - acc: 0.9555 - val_loss: 0.3732 - val_acc: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122c29c50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=4, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're starting to overfit. Adding more dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking model 3\n",
    "\n",
    "Increasing dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Embedding(top_words, embedding_vector_len, input_length=max_review_len))\n",
    "mdl.add(Dropout(0.3))\n",
    "\n",
    "mdl.add(Convolution1D(64, 3, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "mdl.add(Convolution1D(64, 4, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "mdl.add(Convolution1D(64, 5, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "mdl.add(Convolution1D(64, 6, padding='same', activation='relu'))\n",
    "mdl.add(MaxPooling1D(pool_size=2))\n",
    "mdl.add(Flatten())\n",
    "\n",
    "mdl.add(Dropout(0.3))\n",
    "mdl.add(Dense(128, activation='relu'))\n",
    "mdl.add(Dropout(0.3))\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 771s 31ms/step - loss: 0.4964 - acc: 0.7210 - val_loss: 0.3152 - val_acc: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11648f5d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 1992s 80ms/step - loss: 0.3038 - acc: 0.8748 - val_loss: 0.2866 - val_acc: 0.8791\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 839s 34ms/step - loss: 0.2615 - acc: 0.8952 - val_loss: 0.2791 - val_acc: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12543c3d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 822s 33ms/step - loss: 0.2297 - acc: 0.9074 - val_loss: 0.2950 - val_acc: 0.8764\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 771s 31ms/step - loss: 0.2025 - acc: 0.9195 - val_loss: 0.2844 - val_acc: 0.8877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12543c790>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this model is starting to overfit now as well, and didn't perform better than the original configuration of model 3, so going back to the first dropout settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
